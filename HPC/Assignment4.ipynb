{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4\n",
        "Write a CUDA Program for :\n",
        "1. Addition of two large vectors\n",
        "2. Matrix Multiplication using CUDA C\n",
        "\n"
      ],
      "metadata": {
        "id": "NCgtdTQEPVBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing CUDA in Colab"
      ],
      "metadata": {
        "id": "p9JjA47VPaHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pUPhu0UL9bP",
        "outputId": "817c6d7d-956d-490d-eb07-a1eee7a3db81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWFqw-4GL9ZH",
        "outputId": "75517db1-424c-48f4-9238-2b84a8c3cd16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-xx5umbjf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-xx5umbjf\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=655723c0d2f4841dd76e45e772f96358a5fda83aba7888a669bf1eb2bb64257b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-upjwf16d/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEBGw186L9XH",
        "outputId": "ce9ac6bc-9aaa-4b1a-94ce-9f2fe974272d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpvgnorv75\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Program for addition of vectors"
      ],
      "metadata": {
        "id": "x9k_rkTlPeMK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2isMNhnLLxDR",
        "outputId": "a0a02272-9def-46cb-b2e5-b21350bd5689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array 1: 83 86 77 15 93 35 86 92 49 21 62 27 90 59 63 26 40 26 72 36 11 68 67 29 82 30 62 23 67 35 29 2 22 58 69 67 93 56 11 42 29 73 21 19 84 37 98 24 15 70 13 26 91 80 56 73 62 70 96 81 5 25 84 27 36 5 46 29 13 57 24 95 82 45 14 67 34 64 43 50 87 8 76 78 88 84 3 51 54 99 32 60 76 68 39 12 26 86 94 39 95 70 34 78 67 1 97 2 17 92 52 56 1 80 86 41 65 89 44 19 40 29 31 17 97 71 81 75 9 27 67 56 97 53 86 65 6 83 19 24 28 71 32 29 3 19 70 68 8 15 40 49 96 23 18 45 46 51 21 55 79 88 64 28 41 50 93 0 34 64 24 14 87 56 43 91 27 65 59 36 32 51 37 28 75 7 74 21 58 95 29 37 35 93 18 28 43 11 28 29 76 4 43 63 13 38 6 40 4 18 28 88 69 17 17 96 24 43 70 83 90 99 72 25 44 90 5 39 54 86 69 82 42 64 97 7 55 4 48 11 22 28 99 43 46 68 40 22 11 10 5 1 61 30 78 5 20 36 44 26 22 65 8 16 82 58 24 37 62 24 0 36 52 99 79 50 68 71 73 31 81 30 33 94 60 63 99 81 99 96 59 73 13 68 90 95 26 66 84 40 90 84 76 42 36 7 45 56 79 18 87 12 48 72 59 9 36 10 42 87 6 1 13 72 21 55 19 99 21 4 39 11 40 67 5 28 27 50 84 58 20 24 22 69 96 81 30 84 92 72 72 50 25 85 22 99 40 42 98 13 98 90 24 90 9 81 19 36 32 55 94 4 79 69 73 76 50 55 60 42 79 84 93 5 21 67 4 13 61 54 26 59 44 2 2 6 84 21 42 68 \n",
            "Array 2: 28 89 72 8 58 98 36 8 53 48 3 33 33 48 90 54 67 46 68 29 0 46 88 97 49 90 3 33 63 97 53 92 86 25 52 96 75 88 57 29 36 60 14 21 60 4 28 27 50 48 56 2 94 97 99 43 39 2 28 3 0 81 47 38 59 51 35 34 39 92 15 27 4 29 49 64 85 29 43 35 77 0 38 71 49 89 67 88 92 95 43 44 29 90 82 40 41 69 26 32 61 42 60 17 23 61 81 9 90 25 96 67 77 34 90 26 24 57 14 68 5 58 12 86 0 46 26 94 16 52 78 29 46 90 47 70 51 80 31 93 57 27 12 86 14 55 12 90 12 79 10 69 89 74 55 41 20 33 87 88 38 66 70 84 56 17 6 60 49 37 5 59 17 18 45 83 73 58 73 37 89 83 7 78 57 14 71 29 0 59 18 38 25 88 74 33 57 81 93 58 70 99 17 39 69 63 22 94 73 47 31 62 82 90 92 91 57 15 21 57 74 91 47 51 31 21 37 40 54 30 98 25 81 16 16 2 31 39 96 4 38 80 18 21 70 62 12 79 77 85 36 4 76 83 7 59 57 44 99 11 27 50 36 60 18 5 63 49 44 11 5 34 91 75 55 14 89 68 93 18 5 82 22 82 17 30 93 74 26 93 86 53 43 74 14 13 79 77 62 75 88 19 10 32 94 17 46 35 37 91 53 43 73 28 25 91 10 18 17 36 63 55 90 58 30 4 71 61 33 85 89 73 4 51 5 50 68 3 85 6 95 39 49 20 67 26 63 77 96 81 65 60 36 55 70 18 11 42 32 96 79 21 70 84 72 27 34 40 83 72 98 30 63 47 50 30 73 14 59 22 47 24 82 35 32 4 54 43 98 86 40 78 59 62 62 83 41 48 23 24 \n",
            "GPU result:\n",
            "111 175 149 23 151 133 122 100 102 69 65 60 123 107 153 80 107 72 140 65 11 114 155 126 131 120 65 56 130 132 82 94 108 83 121 163 168 144 68 71 65 133 35 40 144 41 126 51 65 118 69 28 185 177 155 116 101 72 124 84 5 106 131 65 95 56 81 63 52 149 39 122 86 74 63 131 119 93 86 85 164 8 114 149 137 173 70 139 146 194 75 104 105 158 121 52 67 155 120 71 156 112 94 95 90 62 178 11 107 117 148 123 78 114 176 67 89 146 58 87 45 87 43 103 97 117 107 169 25 79 145 85 143 143 133 135 57 163 50 117 85 98 44 115 17 74 82 158 20 94 50 118 185 97 73 86 66 84 108 143 117 154 134 112 97 67 99 60 83 101 29 73 104 74 88 174 100 123 132 73 121 134 44 106 132 21 145 50 58 154 47 75 60 181 92 61 100 92 121 87 146 103 60 102 82 101 28 134 77 65 59 150 151 107 109 187 81 58 91 140 164 190 119 76 75 111 42 79 108 116 167 107 123 80 113 9 86 43 144 15 60 108 117 64 116 130 52 101 88 95 41 5 137 113 85 64 77 80 143 37 49 115 44 76 100 63 87 86 106 35 5 70 143 174 134 64 157 139 166 49 86 112 55 176 77 93 192 155 125 189 145 126 56 142 104 108 105 143 146 115 178 103 86 74 130 24 91 91 116 109 140 55 121 100 84 100 46 28 59 123 69 56 103 130 51 59 90 160 54 89 128 84 44 118 10 78 95 53 169 64 115 63 71 89 163 107 93 161 188 153 137 110 61 140 92 117 51 84 130 109 177 111 94 174 81 108 53 76 115 127 192 34 142 116 123 106 123 69 119 64 126 108 175 40 53 71 58 56 159 140 66 137 103 64 64 89 125 69 65 92 \n",
            "Elapsed Time = 0.161344 milliseconds\n",
            "CPU result:\n",
            "111 175 149 23 151 133 122 100 102 69 65 60 123 107 153 80 107 72 140 65 11 114 155 126 131 120 65 56 130 132 82 94 108 83 121 163 168 144 68 71 65 133 35 40 144 41 126 51 65 118 69 28 185 177 155 116 101 72 124 84 5 106 131 65 95 56 81 63 52 149 39 122 86 74 63 131 119 93 86 85 164 8 114 149 137 173 70 139 146 194 75 104 105 158 121 52 67 155 120 71 156 112 94 95 90 62 178 11 107 117 148 123 78 114 176 67 89 146 58 87 45 87 43 103 97 117 107 169 25 79 145 85 143 143 133 135 57 163 50 117 85 98 44 115 17 74 82 158 20 94 50 118 185 97 73 86 66 84 108 143 117 154 134 112 97 67 99 60 83 101 29 73 104 74 88 174 100 123 132 73 121 134 44 106 132 21 145 50 58 154 47 75 60 181 92 61 100 92 121 87 146 103 60 102 82 101 28 134 77 65 59 150 151 107 109 187 81 58 91 140 164 190 119 76 75 111 42 79 108 116 167 107 123 80 113 9 86 43 144 15 60 108 117 64 116 130 52 101 88 95 41 5 137 113 85 64 77 80 143 37 49 115 44 76 100 63 87 86 106 35 5 70 143 174 134 64 157 139 166 49 86 112 55 176 77 93 192 155 125 189 145 126 56 142 104 108 105 143 146 115 178 103 86 74 130 24 91 91 116 109 140 55 121 100 84 100 46 28 59 123 69 56 103 130 51 59 90 160 54 89 128 84 44 118 10 78 95 53 169 64 115 63 71 89 163 107 93 161 188 153 137 110 61 140 92 117 51 84 130 109 177 111 94 174 81 108 53 76 115 127 192 34 142 116 123 106 123 69 119 64 126 108 175 40 53 71 58 56 159 140 66 137 103 64 64 89 125 69 65 92 \n",
            "Elapsed Time = 0.004096 milliseconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include<iostream>\n",
        "#include<bits/stdc++.h>\n",
        "#include<cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "using namespace std;\n",
        "\n",
        "void fill_array(int *arr,int size){\n",
        "    for(int i = 0;i < size; i++){\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void add_cpu(int *arr1, int *arr2, int *result, int size){\n",
        "    for(int i = 0;i < size; i++){\n",
        "        result[i] = arr1[i] + arr2[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *arr, int size){\n",
        "    for(int i = 0; i < size; i++){\n",
        "        cout << arr[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "__global__ void add(int *arr1, int *arr2, int *arr3,int size){\n",
        "    int block_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(block_id < size){\n",
        "        arr3[block_id] = arr1[block_id] + arr2[block_id];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int *arr1_cpu,*arr2_cpu,*result_cpu;\n",
        "    int size = 400;\n",
        "\n",
        "    arr1_cpu = new int[size];\n",
        "    arr2_cpu = new int[size];\n",
        "    result_cpu = new int[size];\n",
        "\n",
        "    fill_array(arr1_cpu,size);\n",
        "    cout << \"Array 1: \";\n",
        "    print_matrix(arr1_cpu,size);\n",
        "    fill_array(arr2_cpu,size);\n",
        "    cout << \"Array 2: \";\n",
        "    print_matrix(arr2_cpu,size);\n",
        "\n",
        "    int *arr1_gpu,*arr2_gpu,*result_gpu;\n",
        "\n",
        "    cudaMallocManaged(&arr1_gpu, size * sizeof(int));\n",
        "    cudaMallocManaged(&arr2_gpu, size * sizeof(int));\n",
        "    cudaMallocManaged(&result_gpu, size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(arr1_gpu,arr1_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(arr2_gpu,arr2_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
        "    cudaEvent_t start,stop;\n",
        "    float elapsedTime;\n",
        "\n",
        "    dim3 dimGrid(size + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "    dim3 dimBlock(BLOCK_SIZE);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "    add<<<dimGrid,dimBlock>>>(arr1_gpu,arr2_gpu,result_gpu,size);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaMemcpy(result_cpu,result_gpu,size * sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    cout << \"GPU result:\\n\";\n",
        "    print_matrix(result_cpu,size);\n",
        "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "    cudaFree(arr1_gpu);\n",
        "    cudaFree(arr2_gpu);\n",
        "    cudaFree(result_gpu);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "    add_cpu(arr1_cpu,arr2_cpu,result_cpu,size);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cout << \"CPU result:\\n\";\n",
        "    print_matrix(result_cpu,size);\n",
        "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA Program for matrix multiplication"
      ],
      "metadata": {
        "id": "a4vP37Y7QICF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include<iostream>\n",
        "#include<bits/stdc++.h>\n",
        "#include<cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "\n",
        "void initialize_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            array[i*cols + j] = rand() % 10;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int *array, int rows, int cols){\n",
        "    for(int i = 0 ; i < rows; i++){\n",
        "        for(int j = 0; j < cols; j++){\n",
        "            cout << array[i*cols + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows,int c_cols){\n",
        "    for(int i = 0; i < c_rows; i++){\n",
        "        for(int j = 0; j < c_cols; j++){\n",
        "            int sum = 0;\n",
        "            for(int k = 0; k < common; k++){\n",
        "                sum += a[i*common + k] * b[k*c_cols + j];\n",
        "            }\n",
        "            c[i*c_cols + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__ void matrix_multiply(int *a, int *b, int *c, int c_rows, int common, int c_cols)\n",
        "{\n",
        "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int sum=0;\n",
        "\n",
        "    if(col < c_cols && row < c_rows) {\n",
        "      for(int j = 0 ;j < common;j++)\n",
        "      {\n",
        "          sum += a[row*common+j] * b[j*c_cols+col];\n",
        "      }\n",
        "      c[c_cols*row+col]=sum;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int A_rows=100, A_cols=8, B_rows=8, B_cols=100, C_rows, C_cols;\n",
        "    cout << \"Dimensions of matrix 1:\\n\";\n",
        "    cout << \"Rows: \";\n",
        "\n",
        "    cout << \"Columns: \";\n",
        "\n",
        "    cout << \"Dimensions of matrix 2:\\n\";\n",
        "    cout << \"Rows: \" << A_cols << endl << \"Columns: \";\n",
        "\n",
        "    B_rows = A_cols;\n",
        "    C_rows = A_rows;\n",
        "    C_cols = B_cols;\n",
        "\n",
        "    int A_size = A_rows * A_cols;\n",
        "    int B_size = B_rows * B_cols;\n",
        "    int C_size = C_rows * C_cols;\n",
        "\n",
        "    int *A, *B, *C;\n",
        "    int *m1,*m2,*result;\n",
        "\n",
        "    A = new int[A_size];\n",
        "    B = new int[B_size];\n",
        "    C = new int[C_size];\n",
        "\n",
        "    initialize_matrix(A,A_rows,A_cols);\n",
        "    cout << \"Matrix 1\\n\";\n",
        "    // print_matrix(A,A_rows,A_cols);\n",
        "    initialize_matrix(B,B_rows,B_cols);\n",
        "    cout << \"Matrix 2\\n\";\n",
        "    //print_matrix(B,B_rows,B_cols);\n",
        "\n",
        "    cudaMallocManaged(&m1, A_size * sizeof(int));\n",
        "    cudaMallocManaged(&m2, B_size * sizeof(int));\n",
        "    cudaMallocManaged(&result, C_size * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(m1,A,A_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(m2,B,B_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimGrid(A_rows + BLOCK_SIZE  - 1 / BLOCK_SIZE, B_cols + BLOCK_SIZE - 1 / BLOCK_SIZE);\n",
        "    dim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\n",
        "    float gpu_elapsed_time;\n",
        "    cudaEvent_t gpu_start,gpu_stop;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiply<<<dimGrid,dimBlock>>>(m1,m2,result,C_rows,A_cols,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    cout << \"GPU result:\\n\";\n",
        "    // print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaEventCreate(&gpu_start);\n",
        "    cudaEventCreate(&gpu_stop);\n",
        "    cudaEventRecord(gpu_start);\n",
        "    matrix_multiplication_cpu(A,B,C,A_cols,C_rows,C_cols);\n",
        "    cudaEventRecord(gpu_stop);\n",
        "    cudaEventSynchronize(gpu_stop);\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
        "    cudaEventDestroy(gpu_start);\n",
        "    cudaEventDestroy(gpu_stop);\n",
        "\n",
        "    cout << \"CPU result:\\n\";\n",
        "    // print_matrix(C,C_rows,C_cols);\n",
        "    cout<<\"CPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
        "\n",
        "    cudaFree(m1);\n",
        "    cudaFree(m2);\n",
        "    cudaFree(result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKONXc0IPSZC",
        "outputId": "711b0d9a-9298-4006-9e8d-e13d17b89fa9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of matrix 1:\n",
            "Rows: Columns: Dimensions of matrix 2:\n",
            "Rows: 8\n",
            "Columns: Matrix 1\n",
            "Matrix 2\n",
            "GPU result:\n",
            "GPU Elapsed time is: 0.229376 milliseconds\n",
            "CPU result:\n",
            "CPU Elapsed time is: 0.269792 milliseconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}